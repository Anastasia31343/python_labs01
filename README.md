# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ1
## –í–≤–æ–¥/–≤—ã–≤–æ–¥ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Python

# –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã:
–û—Å–≤–æ–∏—Ç—å –±–∞–∑–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤–≤–æ–¥–∞-–≤—ã–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö, —Ä–∞–±–æ—Ç—É —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–∞ –≤ Python.

## –ó–∞–¥–∞–Ω–∏–µ 1: –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –≤–æ–∑—Ä–∞—Å—Ç

**–§–∞–π–ª:** `src/01_greeting.py`  

**–¶–µ–ª—å:** –†–∞–±–æ—Ç–∞ —Å–æ —Å—Ç—Ä–æ–∫–∞–º–∏ –∏ —Ü–µ–ª—ã–º–∏ —á–∏—Å–ª–∞–º–∏, –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è —Å—Ç—Ä–æ–∫.

**–í–≤–æ–¥:**
- –ò–º—è (—Å—Ç—Ä–æ–∫–∞)
- –í–æ–∑—Ä–∞—Å—Ç (—Ü–µ–ª–æ–µ —á–∏—Å–ª–æ)

**–í—ã–≤–æ–¥:**
![alt text](images/lab01/image01.png)

**–ü—Ä–∏–º–µ—Ä:**
–ò–º—è: –ê–ª–∏—Å–∞
–í–æ–∑—Ä–∞—Å—Ç: 19
–ü—Ä–∏–≤–µ—Ç, –ê–ª–∏—Å–∞! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç 20.
# –ó–∞–¥–∞–Ω–∏–µ 2: –°—É–º–º–∞ –∏ —Å—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ

**–§–∞–π–ª:** `src/02_sum_avg.py`  

**–¶–µ–ª—å:** –†–∞–±–æ—Ç–∞ —Å –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–∞.

**–í–≤–æ–¥:**
- –î–≤–∞ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —á–∏—Å–ª–∞ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ—á–∫–∞ –∏ –∑–∞–ø—è—Ç–∞—è)

**–í—ã–≤–æ–¥:**
![alt text](images/lab01/image02.png)

**–ü—Ä–∏–º–µ—Ä:**
a: 3,5
b: 4.25
sum=7.75; avg=3.88   
**–ó–∞–¥–∞–Ω–∏–µ 3**: –†–∞—Å—á–µ—Ç —á–µ–∫–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π –∏ –ù–î–°

**–§–∞–π–ª:** `src/03_discount_vat.py`  

**–¶–µ–ª—å:** –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª, —Å–ª–æ–∂–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–∞.

**–§–æ—Ä–º—É–ª—ã:**
- `base = price * (1 - discount/100)`
- `vat_amount = base * (vat/100)`
- `total = base + vat_amount`

**–í–≤–æ–¥:**
- –¶–µ–Ω–∞ (–≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ)
- –°–∫–∏–¥–∫–∞ (%) (–≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ)
- –ù–î–° (%) (–≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ)

**–í—ã–≤–æ–¥:**
![alt text](images/lab01/image03.png)

**–ü—Ä–∏–º–µ—Ä:**
price (‚ÇΩ): 1000
discount (%): 10
vat (%): 20
#   –ó–∞–¥–∞–Ω–∏–µ 4: –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –º–∏–Ω—É—Ç –≤ —á–∞—Å—ã –∏ –º–∏–Ω—É—Ç—ã

**–§–∞–π–ª:** `src/04_minutes_to_hhmm.py`  

**–¶–µ–ª—å:** –†–∞–±–æ—Ç–∞ —Å —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–º –¥–µ–ª–µ–Ω–∏–µ–º, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏.

**–í–≤–æ–¥:**
- –ú–∏–Ω—É—Ç—ã (—Ü–µ–ª–æ–µ —á–∏—Å–ª–æ)

**–í—ã–≤–æ–¥:**
![alt text](images/lab01/image04.png)

**–ü—Ä–∏–º–µ—Ä:**
–ú–∏–Ω—É—Ç—ã: 135
2:15

#   –ó–∞–¥–∞–Ω–∏–µ 5: –ò–Ω–∏—Ü–∏–∞–ª—ã –∏ –¥–ª–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏


**–§–∞–π–ª:** `src/05_initials_and_len.py`
 
**–¶–µ–ª—å:** –†–∞–±–æ—Ç–∞ —Å–æ —Å—Ç—Ä–æ–∫–∞–º–∏, –º–µ—Ç–æ–¥–∞–º–∏ —Å—Ç—Ä–æ–∫, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ.

**–í–≤–æ–¥:**

 –§–ò–û –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π (–º–æ–≥—É—Ç –±—ã—Ç—å –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã)

**–í—ã–≤–æ–¥:**

![alt text](images/lab01/image05.png)


**–ü—Ä–∏–º–µ—Ä:**

–§–ò–û: –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á
–ò–Ω–∏—Ü–∏–∞–ª—ã: –ò–ò–ò.
–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤): 20

**–°—Ç—É–¥–µ–Ω—Ç:** –ù–∏–∫–∏—Ñ–æ—Ä–æ–≤–∞ –ê–Ω–∞—Å—Ç–∞—Å–∏—è –°–µ—Ä–≥–µ–µ–≤–Ω–∞
**–ì—Ä—É–ø–ø–∞:** [–ë–ò–í–¢-25-4]  
**–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å:** [–ñ—É—Ä–∞–∫–æ–≤—Å–∫–∏–π –ö.–í]
 
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ2
## –ö–æ–ª–ª–µ–∫—Ü–∏–∏ –∏ –º–∞—Ç—Ä–∏—Ü—ã (list/tuple/set/dict)
# –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã:
–û—Å–≤–æ–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ —Å–ø–∏—Å–∫–∞–º–∏, –∫–æ—Ä—Ç–µ–∂–∞–º–∏, –º–Ω–æ–∂–µ—Å—Ç–≤–∞–º–∏ –∏ —Å–ª–æ–≤–∞—Ä—è–º–∏.
–ù–∞—É—á–∏—Ç—å—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å —Å 2D-—Å–ø–∏—Å–∫–∞–º–∏ (–º–∞—Ç—Ä–∏—Ü–∞–º–∏) ‚Äî —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, —Å—É–º–º—ã –ø–æ —Å—Ç—Ä–æ–∫–∞–º/—Å—Ç–æ–ª–±—Ü–∞–º.
–ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å–µ–π (–Ω–∞ –ø—Ä–∏–º–µ—Ä–µ —Å—Ç—É–¥–µ–Ω—Ç–∞).

## –ó–∞–¥–∞–Ω–∏–µ 1: arrays.py

**–§–∞–π–ª:** `src/lab02/–∑–∞–¥–∞–Ω–∏–µ 1.1.py`  

**–¶–µ–ª—å:** –í–µ—Ä–Ω—É—Ç—å –∫–æ—Ä—Ç–µ–∂ (–º–∏–Ω–∏–º—É–º, –º–∞–∫—Å–∏–º—É–º). –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç ‚Äî ValueError.

**–í–≤–æ–¥ –≤ min_max:**
- [3, -1, 5, 5, 0]
- [42]
- [-5, -2, -9]
- []
- [1.5, 2, 2.0, -3.1]

**–í—ã–≤–æ–¥:**
![alt text](images/lab02/image11.png)

**–§–∞–π–ª:** `src/lab02/–∑–∞–¥–∞–Ω–∏–µ 1.2.py`

**–¶–µ–ª—å:** –í–µ—Ä–Ω—É—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é).


**–í–≤–æ–¥ –≤ unique_sorted:**
- [3, 1, 2, 1, 3]
- []
- [-1, -1, 0, 2, 2]
- [1.0, 1, 2.5, 2.5, 0]

**–í—ã–≤–æ–¥:**
![alt text](images/lab02/image12.png)

**–§–∞–π–ª:** `src/lab02/–∑–∞–¥–∞–Ω–∏–µ 1.3.py`

**–¶–µ–ª—å:**¬´–†–∞—Å–ø–ª—é—â–∏—Ç—å¬ª —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤/–∫–æ—Ä—Ç–µ–∂–µ–π –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ –ø–æ —Å—Ç—Ä–æ–∫–∞–º (row-major). –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∞—Å—å —Å—Ç—Ä–æ–∫–∞/—ç–ª–µ–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º/–∫–æ—Ä—Ç–µ–∂–µ–º ‚Äî TypeError.


**–í–≤–æ–¥ –≤ flatten:**
- [[1, 2], [3, 4]]
- [[1, 2], (3, 4, 5)]
- [[1], [], [2, 3]]
- [[1, 2], "ab"]

**–í—ã–≤–æ–¥:**
![alt text](images/lab02/image13.png)

# –ó–∞–¥–∞–Ω–∏–µ B: matrix.py

**–§–∞–π–ª:** `src/lab02/–∑–∞–¥–∞–Ω–∏–µ B.1.py`

**–¶–µ–ª—å:** –ü–æ–º–µ–Ω—è—Ç—å —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç–æ–ª–±—Ü—ã –º–µ—Å—Ç–∞–º–∏. –ü—É—Å—Ç–∞—è –º–∞—Ç—Ä–∏—Ü–∞ [] ‚Üí [].
–ï—Å–ª–∏ –º–∞—Ç—Ä–∏—Ü–∞ ¬´—Ä–≤–∞–Ω–∞—è¬ª (—Å—Ç—Ä–æ–∫–∏ —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã) ‚Äî ValueError.
  

**–í–≤–æ–¥ –≤ transpose:**
- [[1, 2, 3]]
- [[1], [2], [3]]
- [[1, 2], [3, 4]]
- []
- [[1, 2], [3]]

**–í—ã–≤–æ–¥:**
![alt text](image-3.png)

**–§–∞–π–ª:** `src/lab02/–∑–∞–¥–∞–Ω–∏–µ B.2.py`

**–¶–µ–ª—å:** –°–¥–µ–ª–∞—Ç—å —Å—É–º–º—É –ø–æ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ. –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ—Å—Ç—å.


**–í–≤–æ–¥ –≤ row_sums:**
- [[1, 2, 3], [4, 5, 6]]
- [[-1, 1], [10, -10]]
- [[0, 0], [0, 0]]
- [[1, 2], [3]]

**–í—ã–≤–æ–¥:**
![alt text](<images/lab02/image B2.png>)

**–§–∞–π–ª:** `src/lab02/–∑–∞–¥–∞–Ω–∏–µ B.3.py`

**–¶–µ–ª—å:** —Å–¥–µ–ª–∞—Ç—å —Å—É–º–º—É –ø–æ –∫–∞–∂–¥–æ–º—É —Å—Ç–æ–ª–±—Ü—É. –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ—Å—Ç—å.


**–í–≤–æ–¥ –≤ col_sums:**
- [[1, 2, 3], [4, 5, 6]]
- [[-1, 1], [10, -10]]
- [[0, 0], [0, 0]]
- [[1, 2], [3]]

**–í—ã–≤–æ–¥:**
![alt text](<images/lab02/image B3.png>)
#   –ó–∞–¥–∞–Ω–∏–µ C: tuples.py

**–§–∞–π–ª:** `src/lab02/–∑–∞–¥–∞–Ω–∏–µ C.1.py`  

**–¶–µ–ª—å:** –û—Å–≤–æ–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—ã–≤–æ–¥–æ–º —á–µ—Ä–µ–∑ –∫–æ—Ä—Ç–µ–∂–∏.

**–í–≤–æ–¥:**
- ("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6)
- ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0)
- ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0)
-  ("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)

**–í—ã–≤–æ–¥:**
![alt text](<images/lab02/image –°1.png>)
**–°—Ç—É–¥–µ–Ω—Ç:** –ù–∏–∫–∏—Ñ–æ—Ä–æ–≤–∞ –ê–Ω–∞—Å—Ç–∞—Å–∏—è –°–µ—Ä–≥–µ–µ–≤–Ω–∞
**–ì—Ä—É–ø–ø–∞:** [–ë–ò–í–¢-25-4]  
**–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å:** [–ñ—É—Ä–∞–∫–æ–≤—Å–∫–∏–π –ö.–í]

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ3
## –¢–µ–∫—Å—Ç—ã –∏ —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ (—Å–ª–æ–≤–∞—Ä—å/–º–Ω–æ–∂–µ—Å—Ç–≤–æ)
# –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã:
–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å, –ø–æ—Å—á–∏—Ç–∞—Ç—å —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –∏ –≤—ã–≤–µ—Å—Ç–∏ —Ç–æ–ø-N.
–°–≤—è–∑—å: –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –õ–†2 (—Ä–∞–±–æ—Ç–∞ —Å–æ —Å–ø–∏—Å–∫–∞–º–∏) –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –õ–†4 (—Ñ–∞–π–ª—ã) ‚Äî –º–æ–¥—É–ª—å lib/text.py –±—É–¥–µ–º –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.

## –ó–∞–¥–∞–Ω–∏–µ A: src/lib/text.py

**–§–∞–π–ª:** `src/lab03/–∑–∞–¥–∞–Ω–∏–µ A.1.py`  

**–¶–µ–ª—å:** 
- –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –µ–¥–∏–Ω–æ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É —á–µ—Ä–µ–∑ casefold –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ Unicode
- –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –±—É–∫–≤—ã "—ë" ‚Üí "–µ" –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–≤
- –û—á–∏—Å—Ç–∫–∞ –æ—Ç —É–ø—Ä–∞–≤–ª—è—é—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ (\t, \r, \n) —Å –∑–∞–º–µ–Ω–æ–π –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤ - —Å—Ö–ª–æ–ø—ã–≤–∞–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –æ–¥–∏–Ω

**–í–≤–æ–¥ –≤ normalize:**
- "–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"
- "—ë–∂–∏–∫, –Å–ª–∫–∞"
- "Hello\r\nWorld"
- "  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "

**–í—ã–≤–æ–¥:**
![alt text](<images/lab03/image A.1.png>)

**–§–∞–π–ª:** `src/lab03/–∑–∞–¥–∞–Ω–∏–µ A.2.py`

**–¶–µ–ª—å:** 
- –í—ã–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–≤ –ø–æ –Ω–µ-–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ñ–∏—Å–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∫–∞–∫ –µ–¥–∏–Ω—ã—Ö —Å–ª–æ–≤ (–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É)
- –í–∫–ª—é—á–µ–Ω–∏–µ —á–∏—Å–µ–ª –∫–∞–∫ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
- –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤ –∫–∞–∫ –Ω–µ-—Å–ª–æ–≤



**–í–≤–æ–¥ –≤ tokenize:**
- "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"
- "hello,world!!!"
- "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"
- "2025 –≥–æ–¥"
- "emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"
**–í—ã–≤–æ–¥:**
![alt text](<images/lab03/image A.2.png>)

**–§–∞–π–ª:** `src/lab03/–∑–∞–¥–∞–Ω–∏–µ A.3.py`

**–¶–µ–ª—å:**
- –ü–æ–¥—Å—á–µ—Ç –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ –∫–∞–∂–¥–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
- –í–æ–∑–≤—Ä–∞—Ç —Å–ª–æ–≤–∞—Ä—è —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ–º —Å–ª–æ–≤–æ ‚Üí –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–π
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —á–µ—Ä–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö

**–í–≤–æ–¥ –≤ count_freq + top_n:**
- ["a", "b", "a", "c", "b", "a"]
- ["bb", "aa", "bb", "aa", "cc"]
- ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä", "–ø—Ä–∏–≤–µ—Ç", "–≤—Å–µ–º", "–º–∏—Ä", "–ø—Ä–µ–∫—Ä–∞—Å–µ–Ω"]

**–í—ã–≤–æ–¥:**
![alt text](<images/lab03/image A.3.png>)

# –ó–∞–¥–∞–Ω–∏–µ B: matrix.py

**–§–∞–π–ª:** `src/lab03/–∑–∞–¥–∞–Ω–∏–µ B.1.py`

**–¶–µ–ª—å:** –°–∫—Ä–∏–ø—Ç —á–∏—Ç–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Ç–µ–∫—Å—Ç–∞ –∏–∑ stdin (–∏–ª–∏ –≤–µ—Å—å –≤–≤–æ–¥ –¥–æ EOF ‚Äî –Ω–∞ –≤–∞—à –≤—ã–±–æ—Ä, –æ–ø–∏—à–∏—Ç–µ –≤ README), –≤—ã–∑—ã–≤–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ lib/text.py –∏ –ø–µ—á–∞—Ç–∞–µ—Ç:
- –í—Å–µ–≥–æ —Å–ª–æ–≤: N
- –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: K
- –¢–æ–ø-5: ‚Äî –ø–æ —Å—Ç—Ä–æ–∫–µ –Ω–∞ –∑–∞–ø–∏—Å—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ª–æ–≤–æ:–∫–æ–ª-–≤–æ (–ø–æ —É–±—ã–≤–∞–Ω–∏—é, –∫–∞–∫ –≤ top_n).

  

**–í–≤–æ–¥ –≤ B:**
- "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!"

**–í—ã–≤–æ–¥:**
![alt text](<images/lab03/image B.1.png>)

**–°—Ç—É–¥–µ–Ω—Ç:** –ù–∏–∫–∏—Ñ–æ—Ä–æ–≤–∞ –ê–Ω–∞—Å—Ç–∞—Å–∏—è –°–µ—Ä–≥–µ–µ–≤–Ω–∞
**–ì—Ä—É–ø–ø–∞:** [–ë–ò–í–¢-25-4]  
**–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å:** [–ñ—É—Ä–∞–∫–æ–≤—Å–∫–∏–π –ö.–í]
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ4
## –§–∞–π–ª—ã: TXT/CSV –∏ –æ—Ç—á—ë—Ç—ã –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ
# –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã:
 –∑–∞–∫—Ä–µ–ø–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å —Ñ–∞–π–ª–∞–º–∏ (—á—Ç–µ–Ω–∏–µ/–∑–∞–ø–∏—Å—å, –∫–æ–¥–∏—Ä–æ–≤–∫–∏), –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–ª–æ–≤–∞–º –∏ –≤—ã–≥—Ä—É–∂–∞—Ç—å –µ—ë –≤ CSV.

## –ó–∞–¥–∞–Ω–∏–µ A:  –º–æ–¥—É–ª—å src/lab04/io_txt_csv.py

**–§–∞–π–ª:** `src/lab04/–∑–∞–¥–∞–Ω–∏–µ –ê1.py`  

**–¶–µ–ª—å:** 
–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å (—Å –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∞–º–∏ –∏ —Ç–∏–ø–∞–º–∏):

1 read_text(path: str | Path, encoding: str = "utf-8") -> str

- –û—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –Ω–∞ —á—Ç–µ–Ω–∏–µ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–µ –∏ –≤–µ—Ä–Ω—É—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∫ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É.

- –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –æ—à–∏–±–∫–∏: –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –ø–æ–¥–Ω–∏–º–∞—Ç—å FileNotFoundError (–ø—É—Å—Ç—å –ø–∞–¥–∞–µ—Ç), –µ—Å–ª–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç ‚Äî –ø–æ–¥–Ω–∏–º–∞—Ç—å UnicodeDecodeError (–ø—É—Å—Ç—å –ø–∞–¥–∞–µ—Ç).

- –ù–û: –≤ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–µ –æ–ø–∏—à–∏—Ç–µ, –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É (–ø—Ä–∏–º–µ—Ä: encoding="cp1251").
2 write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None

- –°–æ–∑–¥–∞—Ç—å/–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å CSV —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ,.
- –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω header, –∑–∞–ø–∏—Å–∞—Ç—å –µ–≥–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π.
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ rows –∏–º–µ–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É (–∏–Ω–∞—á–µ ValueError).

````
import sys
import os

ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, ROOT_DIR)

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))


from lib.text import normalize, tokenize, count_freq, top_n

from pathlib import Path
import csv
from typing import Iterable, Sequence
from collections import Counter


def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    p = Path(path)
    return p.read_text(encoding=encoding)


def write_csv(rows: Iterable[Sequence], path: str | Path,
              header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    rows = list(rows)
    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)


def frequencies_from_text(text: str) -> dict[str, int]:
    tokens = tokenize(normalize(text))
    return Counter(tokens) 


def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]:
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))


txt = read_text("data/input.txt") 
data=[i for i in top_n(count_freq(tokenize(normalize(txt))),n=5)]
write_csv(
    header=("word","count"),
    rows=data,
    path = "data/check.csv" ,
)

````
**–í—ã–≤–æ–¥ 1:**

![alt text](<images/lab04/image A1.png>)

**–í—ã–≤–æ–¥ 2:**

![alt text](<images/lab04/image A2.png>)


# –ó–∞–¥–∞–Ω–∏–µ B: —Å–∫—Ä–∏–ø—Ç src/lab04/text_report.py

**–§–∞–π–ª:** `src/lab04/–∑–∞–¥–∞–Ω–∏–µ –í1.py`

**–¶–µ–ª—å:** –ù–∞–ø–∏—Å–∞—Ç—å —Å–∫—Ä–∏–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π:

1. –ß–∏—Ç–∞–µ—Ç –æ–¥–∏–Ω –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª data/input.txt (–ø—É—Ç—å –º–æ–∂–Ω–æ –∑–∞—Ö–∞—Ä–¥–∫–æ–¥–∏—Ç—å –∏–ª–∏ –ø—Ä–∏–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ‚Äî –æ–ø–∏—à–∏—Ç–µ –≤ README).
2. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç (lib/text.py), —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –∏ —Å—á–∏—Ç–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤.
3. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç data/report.csv c –∫–æ–ª–æ–Ω–∫–∞–º–∏: word,count, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏: count ‚Üì, —Å–ª–æ–≤–æ ‚Üë (–ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ).
4. –í –∫–æ–Ω—Å–æ–ª—å –ø–µ—á–∞—Ç–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ:
- –í—Å–µ–≥–æ —Å–ª–æ–≤: <N>
- –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: <K>
- –¢–æ–ø-5: (—Å–ø–∏—Å–æ–∫ –∏–∑ top_n –∏–∑ –õ–†3)

````
import sys
import os
from pathlib import Path

ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, ROOT_DIR)

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from lib.text import normalize, tokenize, count_freq, top_n

from lab04.io_txt_csv import read_text, write_csv

PROJECT_ROOT = Path(__file__).parent.parent.parent


input_path = PROJECT_ROOT / "data" / "input.txt"
output_path = PROJECT_ROOT / "data" / "report.csv"
p = read_text(input_path)
norm_p=normalize(p)
tokens=tokenize(norm_p)
count_word=count_freq(tokens)
top=top_n(count_freq(tokenize(normalize(p))))

write_csv(top, output_path, ["word", "count"])

print("–í—Å–µ–≥–æ —Å–ª–æ–≤:", len(tokens))
print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤:", len(count_word))
print("–¢–æ–ø-5:")
for x,y in top[:5]:
    print(f'{x}:{y}')
````


**–í—ã–≤–æ–¥:**
![alt text](<images/lab04/image B1.png>)
**–°—Ç—É–¥–µ–Ω—Ç:** –ù–∏–∫–∏—Ñ–æ—Ä–æ–≤–∞ –ê–Ω–∞—Å—Ç–∞—Å–∏—è –°–µ—Ä–≥–µ–µ–≤–Ω–∞
**–ì—Ä—É–ø–ø–∞:** [–ë–ò–í–¢-25-4]  
**–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å:** [–ñ—É—Ä–∞–∫–æ–≤—Å–∫–∏–π –ö.–í]


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ5
## –ó–∞–¥–∞–Ω–∏–µ A (csv_xlsx.py)

```Python
import json
import csv
from pathlib import Path

def json_to_csv(json_path: str, csv_path: str) -> None:
    import json
import csv
from pathlib import Path

def json_to_csv(json_path: str, csv_path: str) -> None:
    if Path(json_path).is_absolute():
        raise ValueError("–ø—É—Ç—å –∫ JSON –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º")
    if Path(csv_path).is_absolute():
        raise ValueError("–ø—É—Ç—å –∫ CSV –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º")
    
    if not json_path.lower().endswith('.json'):
        raise ValueError("–Ω—ç JSON")
    if not csv_path.lower().endswith('.csv'):
        raise ValueError("–Ω—ç CSV")
    
    if not Path(json_path).exists():
        raise FileNotFoundError(f"—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_path}")
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if not data:
        raise ValueError("–ø—É—Å—Ç–æ–π JSON")
    if not isinstance(data, list):
        raise ValueError("JSON –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º")
    if not all(isinstance(item, dict) for item in data):
        raise ValueError("–≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏")
    
    fields = sorted(data[0].keys())
    
    Path(csv_path).parent.mkdir(parents=True, exist_ok=True)
    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fields)
        writer.writeheader()
        for row in data:
            complete_row = {field: str(row.get(field, '')) for field in fields}
            writer.writerow(complete_row)

def csv_to_json(csv_path: str, json_path: str) -> None:
    if not csv_path.lower().endswith('.csv'):
        raise ValueError("–Ω—ç CSV")
    if not json_path.lower().endswith('.json'):
        raise ValueError("–Ω—ç JSON")
    
    if not Path(csv_path).exists():
        raise FileNotFoundError(f"—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        data = list(csv.DictReader(f))
    
    if not data:
        raise ValueError("–ø—É—Å—Ç–æ–π CSV")
    
    Path(json_path).parent.mkdir(parents=True, exist_ok=True)
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    Path("data/out").mkdir(parents=True, exist_ok=True)
    
    json_to_csv("data/samples/people.json", "data/out/people_from_json.csv")
    csv_to_json("data/samples/people.csv", "data/out/people_from_csv.json")
```
![alt text](images/lab05/image(peopl.csv).png)
![alt text](images/lab05/image(people_from_csv.json).png)
![alt text](images/lab05/image(people.json).png)
![alt text](images/lab05/image(people_from_json.csv).png)

## –ó–∞–¥–∞–Ω–∏–µ B (json_csv.py)

``` py
import csv
from pathlib import Path
from openpyxl import Workbook
from openpyxl.utils import get_column_letter

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    if Path(csv_path).is_absolute() or Path(xlsx_path).is_absolute():
        raise ValueError("–ø—É—Ç–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º–∏")
    if not csv_path.endswith('.csv') or not xlsx_path.endswith('.xlsx'):
        raise ValueError("–Ω–µ–≤–µ—Ä–Ω—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤")
    if not Path(csv_path).exists():
        raise FileNotFoundError(f"—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
    
    with open(csv_path, "r", encoding="utf-8") as f:
        rows = list(csv.reader(f))
    
    if not rows or not any(rows[0]):
        raise ValueError("–ø—É—Å—Ç–æ–π CSV –∏–ª–∏ –Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞")
    
    wb = Workbook()
    ws = wb.active
    ws.title = "Sheet1"
    
    max_lengths = []
    for row in rows:
        ws.append(row)
        for i, value in enumerate(row):
            if i >= len(max_lengths):
                max_lengths.append(0)
            max_lengths[i] = max(max_lengths[i], len(str(value or "")))
    
    for i, length in enumerate(max_lengths, 1):
        ws.column_dimensions[get_column_letter(i)].width = max(length + 2, 8)
    
    Path(xlsx_path).parent.mkdir(parents=True, exist_ok=True)
    wb.save(xlsx_path)

if __name__ == "__main__":
    Path("data/out").mkdir(parents=True, exist_ok=True)
    csv_to_xlsx("data/samples/people.csv", "data/out/people.xlsx")
```
![alt text](images/lab05/image(people.csv).png)
![alt text](images/lab05/image(people.xlsx).png)
**–°—Ç—É–¥–µ–Ω—Ç:** –ù–∏–∫–∏—Ñ–æ—Ä–æ–≤–∞ –ê–Ω–∞—Å—Ç–∞—Å–∏—è –°–µ—Ä–≥–µ–µ–≤–Ω–∞
**–ì—Ä—É–ø–ø–∞:** [–ë–ò–í–¢-25-4]  
**–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å:** [–ñ—É—Ä–∞–∫–æ–≤—Å–∫–∏–π –ö.–í]
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ6
## –ó–∞–¥–∞–Ω–∏–µ A (cli_convert.py)

```Python
import argparse
from pathlib import Path
import sys
import json
import csv
import pandas as pd


def json_to_csv(input_file: str, output_file: str):
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not isinstance(data, list):
            data = [data]
        
        if not data:
            raise ValueError("JSON —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π")
        
        fieldnames = list(data[0].keys())
        
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(data)
        
        print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {input_file} ‚Üí {output_file}")
        
    except Exception as e:
        sys.stderr.write(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ JSON‚ÜíCSV: {e}\n")
        sys.exit(1)


def csv_to_json(input_file: str, output_file: str, indent: int = 2):
    try:
        data = []
        with open(input_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                data.append(row)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=indent)
        
        print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {input_file} ‚Üí {output_file}")
        
    except Exception as e:
        sys.stderr.write(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV‚ÜíJSON: {e}\n")
        sys.exit(1)


def csv_to_xlsx(input_file: str, output_file: str, sheet_name: str = "Sheet1"):
    try:
        df = pd.read_csv(input_file)
        df.to_excel(output_file, index=False, sheet_name=sheet_name)
        
        print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {input_file} ‚Üí {output_file}")
        
    except Exception as e:
        sys.stderr.write(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV‚ÜíXLSX: {e}\n")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä JSON‚ÜîCSV, CSV‚ÜíXLSX",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    subparsers = parser.add_subparsers(
        dest="command",
        title="–¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã",
        metavar=""
    )
    subparsers.required = True
    
    json2csv_parser = subparsers.add_parser(
        "json2csv",
        help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –≤ CSV",
        description="–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç JSON —Ñ–∞–π–ª –≤ CSV —Ñ–æ—Ä–º–∞—Ç"
    )
    json2csv_parser.add_argument(
        "--in",
        dest="input",
        required=True,
        help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É JSON"
    )
    json2csv_parser.add_argument(
        "--out",
        dest="output",
        required=True,
        help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV"
    )
    
    csv2json_parser = subparsers.add_parser(
        "csv2json",
        help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ JSON",
        description="–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç CSV —Ñ–∞–π–ª –≤ JSON —Ñ–æ—Ä–º–∞—Ç"
    )
    csv2json_parser.add_argument(
        "--in",
        dest="input",
        required=True,
        help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É CSV"
    )
    csv2json_parser.add_argument(
        "--out",
        dest="output",
        required=True,
        help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É JSON"
    )
    csv2json_parser.add_argument(
        "--indent",
        type=int,
        default=2,
        help="–û—Ç—Å—Ç—É–ø –≤ JSON —Ñ–∞–π–ª–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2)"
    )
    
    csv2xlsx_parser = subparsers.add_parser(
        "csv2xlsx",
        help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ XLSX",
        description="–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç CSV —Ñ–∞–π–ª –≤ Excel —Ñ–æ—Ä–º–∞—Ç"
    )
    csv2xlsx_parser.add_argument(
        "--in",
        dest="input",
        required=True,
        help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É CSV"
    )
    csv2xlsx_parser.add_argument(
        "--out",
        dest="output",
        required=True,
        help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É XLSX"
    )
    csv2xlsx_parser.add_argument(
        "--sheet",
        default="Sheet1",
        help="–ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ –≤ Excel (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: Sheet1)"
    )
    
    args = parser.parse_args()
    
    if not Path(args.input).exists():
        sys.stderr.write(f"–û—à–∏–±–∫–∞: –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª '{args.input}' –Ω–µ –Ω–∞–π–¥–µ–Ω\n")
        sys.exit(1)
    
    if args.command == "json2csv":
        json_to_csv(args.input, args.output)
    elif args.command == "csv2json":
        csv_to_json(args.input, args.output, getattr(args, 'indent', 2))
    elif args.command == "csv2xlsx":
        csv_to_xlsx(args.input, args.output, getattr(args, 'sheet', 'Sheet1'))


if __name__ == "__main__":
    main()
```
![alt text](images/lab06/–≤—ã–≤–æ–¥(cli_convert)01.png)
![alt text](images/lab06/–≤—ã–≤–æ–¥(cli_convert)02.png)
![alt text](images/lab06/–≤—ã–≤–æ–¥(cli_convert)03.png)

## –ó–∞–¥–∞–Ω–∏–µ B (cli_text.py)

``` py
import argparse
from pathlib import Path
import re
from collections import Counter

def normalize(text):
    text = text.lower()
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def tokenize(text):
    return re.findall(r'\b[a-z–∞-—è—ë0-9]+\b', text, re.IGNORECASE)

def count_freq(words):
    freq = {}
    for word in words:
        freq[word] = freq.get(word, 0) + 1
    return freq

def top_n(freq, n=5):
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]


def main():
    parser = argparse.ArgumentParser(description="CLI-—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")

    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã", required=True)

    stats_parser = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ")
    stats_parser.add_argument("--input", required=True, help="–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª")
    stats_parser.add_argument(
        "--top",
        type=int,
        default=5,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø–æ–≤—ã—Ö —Å–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)",
    )
    
    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–æ–¥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    args = parser.parse_args()

    if args.command == "cat":
        file = Path(args.input)
        if not file.exists():
            parser.error(f"–§–∞–π–ª '{args.input}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        with open(file, "r", encoding="utf-8") as f:
            number = 1
            for row in f:
                row = row.rstrip("\n")
                if args.n:  
                    print(f"{number}: {row}")
                    number += 1
                else:
                    print(row)

    elif args.command == "stats":
        file = Path(args.input)
        if not file.exists():
            parser.error(f"–§–∞–π–ª '{args.input}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        with open(file, "r", encoding="utf-8") as f:
            data = f.read()
        
        normalized = normalize(data)
        tokens = tokenize(normalized)
        freq = count_freq(tokens)
        top = top_n(freq, n=args.top)
        print(f"–¢–æ–ø {args.top} —Å–ª–æ–≤:")
        for i, (word, count) in enumerate(top, 1):
            print(f"{i}. {word} - {count}")


if __name__ == "__main__":
    main()
```
![alt text](images/lab06/–≤—ã–≤–æ–¥(cli_text)01.png)
![alt text](images/lab06/–≤—ã–≤–æ–¥(cli_text)02.png)
![alt text](images/lab06/–≤—ã–≤–æ–¥(cli_text)03.png)
**–°—Ç—É–¥–µ–Ω—Ç:** –ù–∏–∫–∏—Ñ–æ—Ä–æ–≤–∞ –ê–Ω–∞—Å—Ç–∞—Å–∏—è –°–µ—Ä–≥–µ–µ–≤–Ω–∞
**–ì—Ä—É–ø–ø–∞:** [–ë–ò–í–¢-25-4]  
**–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å:** [–ñ—É—Ä–∞–∫–æ–≤—Å–∫–∏–π –ö.–í]
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ7
## –ó–∞–¥–∞–Ω–∏–µ A (test_json_csv)
```py
import json, csv
from pathlib import Path
import pytest
import os
import sys

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from .csv_json import json_to_csv, csv_to_json


def write_json(path: Path, obj):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")


def read_csv_rows(path: Path):
    with path.open(encoding="utf-8") as f:
        return list(csv.DictReader(f))


def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [{"name": "Alice", "age": 22}, {"name": "Bob", "age": 25}]
    write_json(src, data)

    json_to_csv(str(src), str(dst))
    rows = read_csv_rows(dst)
    assert len(rows) == 2
    assert set(rows[0]) >= {"name", "age"}


def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"
    src.write_text("name,age\nAlice,22\nBob,25\n", encoding="utf-8")

    csv_to_json(str(src), str(dst))
    obj = json.loads(dst.read_text(encoding="utf-8"))
    assert isinstance(obj, list) and len(obj) == 2
    assert set(obj[0]) == {"name", "age"}


def test_json_to_csv_empty(tmp_path: Path):
    src = tmp_path / "empty.json"
    dst = tmp_path / "empty.csv"
    src.write_text("[]", encoding="utf-8")

    try:
        json_to_csv(str(src), str(dst))
        if dst.exists():
            pass
    except (ValueError, IndexError):
        pass


def test_csv_to_json_empty(tmp_path: Path):
    src = tmp_path / "empty.csv"
    dst = tmp_path / "empty.json"
    src.write_text("", encoding="utf-8")

    try:
        csv_to_json(str(src), str(dst))
        if dst.exists():
            pass
    except (ValueError, Exception):
        pass


def test_missing_file(tmp_path: Path):
    try:
        csv_to_json("nope.csv", str(tmp_path / "out.json"))
        if (tmp_path / "out.json").exists():
            pass
    except FileNotFoundError:
        pass
```
![alt text](images/lab07/test_json_csv.png)
## –ó–∞–¥–∞–Ω–∏–µ –í (test_text)
```py
import pytest
import os
import sys

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from src.lib.text import count_freq, normalize, tokenize, top_n

@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
    ],
)
def test_normalize(src, expected):
    assert normalize(src) == expected


@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
    ],
)
def test_tokenize(src, expected):
    assert tokenize(src) == expected


def test_count_and_top():
    tokens = ["a", "b", "a", "c", "b", "a"]
    freq = count_freq(tokens)
    assert freq == {"a": 3, "b": 2, "c": 1}
    assert top_n(freq, 2) == [("a", 3), ("b", 2)]


def test_top_tie_breaker():
    freq = count_freq(["bb", "aa", "bb", "aa", "cc"])
    assert top_n(freq, 2) == [("aa", 2), ("bb", 2)]


def test_dop():
    assert normalize("") == ""
    assert tokenize("") == []
    assert count_freq([]) == {}
    assert top_n({}, 5) == []


def test_top_dop():
    freq = {"a": 3, "b": 2}
    assert top_n(freq, 5) == [("a", 3), ("b", 2)]
```
![alt text](images/lab07/text_test.png)
**–°—Ç—É–¥–µ–Ω—Ç:** –ù–∏–∫–∏—Ñ–æ—Ä–æ–≤–∞ –ê–Ω–∞—Å—Ç–∞—Å–∏—è –°–µ—Ä–≥–µ–µ–≤–Ω–∞
**–ì—Ä—É–ø–ø–∞:** [–ë–ò–í–¢-25-4]  
**–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å:** [–ñ—É—Ä–∞–∫–æ–≤—Å–∫–∏–π –ö.–í]
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ7
## –ó–∞–¥–∞–Ω–∏–µ A (models.py)
```py
from dataclasses import dataclass, asdict
from datetime import datetime, date
from typing import ClassVar
import re


@dataclass
class Student:
    
    fio: str
    birthdate: str
    group: str
    gpa: float
    
    DATE_FORMAT: ClassVar[str] = "%Y-%m-%d"
    GPA_MIN: ClassVar[float] = 0.0
    GPA_MAX: ClassVar[float] = 5.0
    
    def __post_init__(self):
        self._validate_birthdate()
        self._validate_gpa()
        self._validate_fio()
    
    def _validate_birthdate(self) -> None:
        try:
            datetime.strptime(self.birthdate, self.DATE_FORMAT)
        except ValueError:
            raise ValueError(
                f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {self.birthdate}. "
                f"–û–∂–∏–¥–∞–µ—Ç—Å—è: {self.DATE_FORMAT}"
            )
    
    def _validate_gpa(self) -> None:
        if not (self.GPA_MIN <= self.gpa <= self.GPA_MAX):
            raise ValueError(
                f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª {self.gpa} –≤–Ω–µ –¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ "
                f"[{self.GPA_MIN}, {self.GPA_MAX}]"
            )
    
    def _validate_fio(self) -> None:
        if not self.fio or not self.fio.strip():
            raise ValueError("–§–ò–û –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    
    def age(self) -> int:

        birth_date = datetime.strptime(self.birthdate, self.DATE_FORMAT).date()
        today = date.today()
        
        age = today.year - birth_date.year
        
        if (today.month, today.day) < (birth_date.month, birth_date.day):
            age -= 1
        
        return age
    
    def to_dict(self) -> dict:
        return {
            "fio": self.fio,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa,
            "age": self.age()  
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'Student':
        
        student_data = {
            "fio": data["fio"],
            "birthdate": data["birthdate"],
            "group": data["group"],
            "gpa": float(data["gpa"]) 
        }
        return cls(**student_data)
    
    def __str__(self) -> str:
        return (f"–°—Ç—É–¥–µ–Ω—Ç: {self.fio}\n"
                f"–ì—Ä—É–ø–ø–∞: {self.group}\n"
                f"–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è: {self.birthdate} (–≤–æ–∑—Ä–∞—Å—Ç: {self.age()} –ª–µ—Ç)\n"
                f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: {self.gpa:.2f}")
    
    def __repr__(self) -> str:
        return (f"Student(fio={self.fio!r}, "
                f"birthdate={self.birthdate!r}, "
                f"group={self.group!r}, "
                f"gpa={self.gpa})")


if __name__ == "__main__":
    try:
        student1 = Student(
            fio="–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á",
            birthdate="2000-05-15",
            group="SE-01",
            gpa=4.2
        )
        
        print("=== –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã –∫–ª–∞—Å—Å–∞ Student ===")
        print(student1)
        print()
        
        print("–°–ª–æ–≤–∞—Ä—å –∏–∑ –æ–±—ä–µ–∫—Ç–∞:")
        print(student1.to_dict())
        print()
        
        print("–û–±—ä–µ–∫—Ç –∏–∑ —Å–ª–æ–≤–∞—Ä—è:")
        student_dict = {
            "fio": "–ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á",
            "birthdate": "1999-11-30",
            "group": "CS-02",
            "gpa": 3.8
        }
        student2 = Student.from_dict(student_dict)
        print(student2)
        
    except ValueError as e:
        print(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
```
![alt text](images/lab08/models.png)
## –ó–∞–¥–∞–Ω–∏–µ B (serialize.py)
```py
import json
from pathlib import Path
from typing import List
try:
    from models import Student
except ImportError:
    from .models import Student


def students_to_json(students: List[Student], path: str) -> None:
   
    if not students:
        raise ValueError("–°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç")
    
    data = [student.to_dict() for student in students]
    
    try:
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {path}")
    except IOError as e:
        raise IOError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å —Ñ–∞–π–ª {path}: {e}")


def students_from_json(path: str) -> List[Student]:
    
    if not Path(path).exists():
        raise FileNotFoundError(f"–§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –≤ —Ñ–∞–π–ª–µ {path}: {e}")
    except IOError as e:
        raise IOError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {path}: {e}")
    
    if not isinstance(data, list):
        raise ValueError(f"–û–∂–∏–¥–∞–ª—Å—è —Å–ø–∏—Å–æ–∫ –≤ —Ñ–∞–π–ª–µ {path}, –ø–æ–ª—É—á–µ–Ω {type(data)}")
    
    students = []
    errors = []
    
    for i, item in enumerate(data):
        try:
            student = Student.from_dict(item)
            students.append(student)
        except (ValueError, KeyError) as e:
            errors.append(f"–°—Ç—Ä–æ–∫–∞ {i}: {e}")
    
    if errors:
        error_msg = "\n".join(errors)
        raise ValueError(f"–û—à–∏–±–∫–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö:\n{error_msg}")
    
    return students


if __name__ == "__main__":
    try:
        students = [
            Student("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "2000-05-15", "SE-01", 4.2),
            Student("–ü–µ—Ç—Ä–æ–≤–∞ –ê–Ω–Ω–∞ –°–µ—Ä–≥–µ–µ–≤–Ω–∞", "2001-08-22", "CS-02", 4.8),
            Student("–°–∏–¥–æ—Ä–æ–≤ –ê–ª–µ–∫—Å–µ–π –ü–µ—Ç—Ä–æ–≤–∏—á", "1999-11-30", "AI-03", 3.5),
        ]
        
        import os
        current_dir = os.path.dirname(__file__)
        output_path = os.path.join(current_dir, "..", "..", "data", "lab08", "students_output.json")
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        students_to_json(students, output_path)
        print(f"\n–°—Ç—É–¥–µ–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
        
        print("\n–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞...")
        loaded_students = students_from_json(output_path)
        
        print(f"\n–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(loaded_students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤:")
        for student in loaded_students:
            print("-" * 30)
            print(student)
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
```
![alt text](images/lab08/serialize.png)
**–°—Ç—É–¥–µ–Ω—Ç:** –ù–∏–∫–∏—Ñ–æ—Ä–æ–≤–∞ –ê–Ω–∞—Å—Ç–∞—Å–∏—è –°–µ—Ä–≥–µ–µ–≤–Ω–∞
**–ì—Ä—É–ø–ø–∞:** [–ë–ò–í–¢-25-4]  
**–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å:** [–ñ—É—Ä–∞–∫–æ–≤—Å–∫–∏–π –ö.–í]